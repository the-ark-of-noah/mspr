{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-18T09:55:20.340227Z",
     "start_time": "2024-04-18T09:55:20.337598Z"
    }
   },
   "source": "# Quelle est l'influence combinée des facteurs démographiques, économiques, de sécurité et sociaux sur les résultats des élections présidentielles de 2022 en France, par code postal?",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T09:55:20.359118Z",
     "start_time": "2024-04-18T09:55:20.357258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Ajout d'une tranche d'age dans la démographie\n",
    "# Faire le ratio entre le niveau de vie et le niveau de chomage\n",
    "# Ajouter le taux de criminalité"
   ],
   "id": "977dbff1c3ec5090",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T09:55:20.372396Z",
     "start_time": "2024-04-18T09:55:20.370356Z"
    }
   },
   "cell_type": "code",
   "source": "# Ajout d'une tranche d'age dans la démographie",
   "id": "c950326e6b0933d0",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T10:48:07.585403Z",
     "start_time": "2024-04-18T10:47:01.447243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from models.managers.db_manager import connect_to_bdd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Création des requêtes SQL et des dataframes\n",
    "conn = connect_to_bdd()\n",
    "\n",
    "query_demo = \"SELECT * FROM demographie\"\n",
    "df_densite = pd.read_sql(query_demo, conn)\n",
    "\n",
    "query_economie = \"SELECT * FROM economie\"\n",
    "df_economie = pd.read_sql(query_economie, conn)\n",
    "\n",
    "query_securite = \"SELECT * FROM securite\"\n",
    "df_securite = pd.read_sql(query_securite, conn)\n",
    "\n",
    "query_social = \"SELECT * FROM social\"\n",
    "df_social = pd.read_sql(query_social, conn)\n",
    "\n",
    "query_election_t1 = \"SELECT * FROM election_2022_t1\"\n",
    "df_election_t1 = pd.read_sql(query_election_t1, conn)\n",
    "\n",
    "# Fermer la connexion\n",
    "conn.close()\n",
    "\n",
    "# Assumons que les connexions et requêtes sont déjà faites et les dataframes sont chargés comme df_densite, df_economie, df_securite, df_social, df_election_t1\n",
    "\n",
    "# Aggrégation des données\n",
    "df_densite = df_densite.groupby('code_postal')['dens_pop'].mean().reset_index()\n",
    "df_securite = df_securite.groupby('code_postal')['tauxpourcent'].mean().reset_index()\n",
    "\n",
    "# Fusionner les dataframes sur 'code_postal'\n",
    "df_merged = pd.merge(df_densite, df_economie, on='code_postal', how='inner')\n",
    "df_merged = pd.merge(df_merged, df_securite, on='code_postal', how='inner')\n",
    "df_merged = pd.merge(df_merged, df_social, on='code_postal', how='inner')\n",
    "df_merged = pd.merge(df_merged, df_election_t1, on='code_postal', how='inner')\n",
    "\n",
    "# Assumons que 'winner' est une colonne dans df_election_t1 qui indique le parti gagnant\n",
    "# Calculer le ratio entre le niveau de vie médian et le taux de chômage\n",
    "df_merged['ratio_vie_chomage'] = df_merged['Médiane du niveau de vie 2021'] / df_merged['avg_2022']\n",
    "df_merged['taux_criminalite'] = df_merged['tauxpourcent']\n",
    "\n",
    "### Étape 2 : Encodage des caractéristiques catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df_merged.select_dtypes(include=['object']).columns:\n",
    "    df_merged[column] = label_encoder.fit_transform(df_merged[column])\n",
    "\n",
    "### Étape 3 : Préparation des données pour XGBoost\n",
    "X = df_merged.drop(['winner', 'code_postal'], axis=1)  # Supprimez 'winner' et 'code_postal'\n",
    "y = label_encoder.fit_transform(df_merged['winner'])\n",
    "\n",
    "### Étape 4 : Split des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "### Étape 5 : Configuration et entraînement du modèle XGBoost\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(y)), seed=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "### Étape 6 : Prédiction et évaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "### Étape 7 : Feature importance\n",
    "importance = model.feature_importances_\n",
    "features = pd.DataFrame({'Feature': X.columns, 'Importance': importance}).sort_values(by='Importance', ascending=False)\n",
    "print(features)\n",
    "\n",
    "### Étape 8 : Optimisation avec GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Meilleurs paramètres: \", grid_search.best_params_)\n",
    "print(\"Meilleure précision: {:.2f}%\".format(grid_search.best_score_ * 100))"
   ],
   "id": "db19ce01f9f181af",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9z/lnzs0dyx0k1g2nvs92hf0syr0000gn/T/ipykernel_25388/2285983127.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_densite = pd.read_sql(query_demo, conn)\n",
      "/var/folders/9z/lnzs0dyx0k1g2nvs92hf0syr0000gn/T/ipykernel_25388/2285983127.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_economie = pd.read_sql(query_economie, conn)\n",
      "/var/folders/9z/lnzs0dyx0k1g2nvs92hf0syr0000gn/T/ipykernel_25388/2285983127.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_securite = pd.read_sql(query_securite, conn)\n",
      "/var/folders/9z/lnzs0dyx0k1g2nvs92hf0syr0000gn/T/ipykernel_25388/2285983127.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_social = pd.read_sql(query_social, conn)\n",
      "/var/folders/9z/lnzs0dyx0k1g2nvs92hf0syr0000gn/T/ipykernel_25388/2285983127.py:25: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_election_t1 = pd.read_sql(query_election_t1, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00      5175\n",
      "           3       1.00      1.00      1.00     22948\n",
      "           4       1.00      1.00      1.00        27\n",
      "           5       1.00      1.00      1.00        26\n",
      "           6       1.00      1.00      1.00        23\n",
      "           7       1.00      1.00      1.00         9\n",
      "           8       1.00      1.00      1.00     38971\n",
      "           9       1.00      1.00      1.00        52\n",
      "          10       1.00      1.00      1.00       446\n",
      "\n",
      "    accuracy                           1.00     67698\n",
      "   macro avg       1.00      1.00      1.00     67698\n",
      "weighted avg       1.00      1.00      1.00     67698\n",
      "\n",
      "[[    6     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0    15     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0  5175     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0 22948     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0    27     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0    26     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0    23     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     9     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0 38971     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0    52     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0   446]]\n",
      "              Feature  Importance\n",
      "99       % Voix/Exp 5    0.241911\n",
      "101      % Voix/Exp 7    0.189619\n",
      "85       % Voix/Ins 3    0.172046\n",
      "97       % Voix/Exp 3    0.122635\n",
      "87       % Voix/Ins 5    0.080400\n",
      "..                ...         ...\n",
      "72            Parti 2    0.000000\n",
      "71            Parti 1    0.000000\n",
      "59                 an    0.000000\n",
      "56                age    0.000000\n",
      "109  taux_criminalite    0.000000\n",
      "\n",
      "[110 rows x 2 columns]\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] END ........................................max_depth=3; total time=   4.7s\n",
      "[CV] END ........................................max_depth=3; total time=   5.2s\n",
      "[CV] END ........................................max_depth=3; total time=   5.1s\n",
      "[CV] END ........................................max_depth=5; total time=   5.4s\n",
      "[CV] END ........................................max_depth=5; total time=   5.6s\n",
      "[CV] END ........................................max_depth=5; total time=   6.0s\n",
      "[CV] END ........................................max_depth=7; total time=   5.6s\n",
      "[CV] END ........................................max_depth=7; total time=   5.1s\n",
      "[CV] END ........................................max_depth=7; total time=   5.3s\n",
      "Meilleurs paramètres:  {'max_depth': 7}\n",
      "Meilleure précision: 99.99%\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1ce8e8d767e7b591"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
