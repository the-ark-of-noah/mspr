{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-18T09:55:20.340227Z",
     "start_time": "2024-04-18T09:55:20.337598Z"
    }
   },
   "source": "# Quelle est l'influence combinée des facteurs démographiques, économiques, de sécurité et sociaux sur les résultats des élections présidentielles de 2022 en France, par code postal?",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T09:55:20.359118Z",
     "start_time": "2024-04-18T09:55:20.357258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Ajout d'une tranche d'age dans la démographie\n",
    "# Faire le ratio entre le niveau de vie et le niveau de chomage\n",
    "# Ajouter le taux de criminalité"
   ],
   "id": "977dbff1c3ec5090",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T09:55:20.372396Z",
     "start_time": "2024-04-18T09:55:20.370356Z"
    }
   },
   "cell_type": "code",
   "source": "# Ajout d'une tranche d'age dans la démographie",
   "id": "c950326e6b0933d0",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T22:21:10.608942Z",
     "start_time": "2024-04-20T16:27:18.396212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from models.managers.db_manager import connect_to_bdd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Création des requêtes SQL et des dataframes\n",
    "conn = connect_to_bdd()\n",
    "\n",
    "query_demo = \"SELECT * FROM demographie\"\n",
    "df_densite = pd.read_sql(query_demo, conn)\n",
    "\n",
    "query_economie = \"SELECT * FROM economie\"\n",
    "df_economie = pd.read_sql(query_economie, conn)\n",
    "\n",
    "query_securite = \"SELECT * FROM securite\"\n",
    "df_securite = pd.read_sql(query_securite, conn)\n",
    "\n",
    "query_social = \"SELECT * FROM social\"\n",
    "df_social = pd.read_sql(query_social, conn)\n",
    "\n",
    "query_election_t1 = \"SELECT * FROM election_2022_t1\"\n",
    "df_election_t1 = pd.read_sql(query_election_t1, conn)\n",
    "\n",
    "# Fermer la connexion\n",
    "conn.close()\n",
    "\n",
    "# Assumons que les connexions et requêtes sont déjà faites et les dataframes sont chargés comme df_densite, df_economie, df_securite, df_social, df_election_t1\n",
    "\n",
    "# Aggrégation des données\n",
    "df_densite = df_densite.groupby('code_postal')['dens_pop'].mean().reset_index()\n",
    "df_securite = df_securite.groupby('code_postal')['tauxpourcent'].mean().reset_index()\n",
    "\n",
    "# Fusionner les dataframes sur 'code_postal'\n",
    "df_merged = pd.merge(df_densite, df_economie, on='code_postal', how='inner')\n",
    "df_merged = pd.merge(df_merged, df_securite, on='code_postal', how='inner')\n",
    "df_merged = pd.merge(df_merged, df_social, on='code_postal', how='inner')\n",
    "df_merged = pd.merge(df_merged, df_election_t1, on='code_postal', how='inner')\n",
    "\n",
    "# Assumons que 'winner' est une colonne dans df_election_t1 qui indique le parti gagnant\n",
    "# Calculer le ratio entre le niveau de vie médian et le taux de chômage\n",
    "df_merged['ratio_vie_chomage'] = df_merged['Médiane du niveau de vie 2021'] / df_merged['avg_2022']\n",
    "df_merged['taux_criminalite'] = df_merged['tauxpourcent']\n",
    "\n",
    "### Étape 2 : Encodage des caractéristiques catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df_merged.select_dtypes(include=['object']).columns:\n",
    "    df_merged[column] = label_encoder.fit_transform(df_merged[column])\n",
    "\n",
    "### Étape 3 : Préparation des données pour XGBoost\n",
    "X = df_merged.drop(['winner', 'code_postal'], axis=1)  # Supprimez 'winner' et 'code_postal'\n",
    "y = label_encoder.fit_transform(df_merged['winner'])\n",
    "\n",
    "### Étape 4 : Split des données\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Augmenter la taille de l'ensemble de test pour un meilleur test de généralisation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "### Étape 5 : Configuration et entraînement du modèle XGBoost\n",
    "# model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(y)), seed=42)\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=1000,  # Nombre d'arbres\n",
    "    learning_rate=0.1,  # Taux d'apprentissage\n",
    "    objective='multi:softmax',  # Classification multi-classe\n",
    "    num_class=len(set(y)),  # Nombre de classes\n",
    "    seed=42,  # Seed pour la reproductibilité\n",
    "    max_depth=3,  # Réduire la profondeur des arbres : par défaut à 6\n",
    "    reg_alpha=0.1,  # L1 regularization pour réduire le surajustement\n",
    "    reg_lambda=1.0,  # L2 regularization\n",
    "    gamma=0.1,  # Pénalité minimale pour faire une nouvelle partition sur un nœud feuille\n",
    "    subsample=0.8,  # Sous-échantillonnage des lignes pour chaque arbre\n",
    "    colsample_bytree=0.8,  # Sous-échantillonnage des colonnes pour chaque arbre\n",
    "    eval_metric='merror'  # Métrique d'évaluation\n",
    "    # early_stopping_rounds=10 # Arrêter l'entraînement si aucune amélioration n'est observée après 10 itérations\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Best iteration: \", model.best_iteration)\n",
    "\n",
    "### Étape 6 : Prédiction et évaluation\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Validation croisée pour évaluer la performance du modèle\n",
    "cv_scores = cross_val_score(model, X, y, cv=3)\n",
    "print(f\"CV Mean Score: {np.mean(cv_scores):.2f}%\")\n",
    "\n",
    "### Étape 7 : Feature importance\n",
    "importance = model.feature_importances_\n",
    "features = pd.DataFrame({'Feature': X.columns, 'Importance': importance}).sort_values(by='Importance', ascending=False)\n",
    "print(features)\n",
    "\n",
    "### Étape 8 : Optimisation avec GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],  # Profondeur maximale de l'arbre\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Taux d'apprentissage\n",
    "    'subsample': [0.6, 0.8, 1.0],  # Sous-échantillonnage des lignes pour chaque arbre\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],  # Sous-échantillonnage des colonnes pour chaque arbre\n",
    "    'n_estimators': [100, 200, 300],  # Nombre d'arbres\n",
    "    'reg_alpha': [0, 0.1, 0.5],  # L1 regularization\n",
    "    'reg_lambda': [1, 1.5, 2]  # L2 regularization\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3, verbose=2, n_jobs=-1)  # 3-fold cross-validation\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Meilleurs paramètres: \", grid_search.best_params_)\n",
    "print(\"Meilleure précision: {:.2f}%\".format(grid_search.best_score_ * 100))\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(\"Précision du meilleur modèle sur l'ensemble de test: {:.2f}%\".format(accuracy_score(y_test, y_pred_best) * 100))\n"
   ],
   "id": "db19ce01f9f181af",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/t_t93b0n0wx8m9fcms_xg6640000gn/T/ipykernel_4397/2007906347.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_densite = pd.read_sql(query_demo, conn)\n",
      "/var/folders/00/t_t93b0n0wx8m9fcms_xg6640000gn/T/ipykernel_4397/2007906347.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_economie = pd.read_sql(query_economie, conn)\n",
      "/var/folders/00/t_t93b0n0wx8m9fcms_xg6640000gn/T/ipykernel_4397/2007906347.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_securite = pd.read_sql(query_securite, conn)\n",
      "/var/folders/00/t_t93b0n0wx8m9fcms_xg6640000gn/T/ipykernel_4397/2007906347.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_social = pd.read_sql(query_social, conn)\n",
      "/var/folders/00/t_t93b0n0wx8m9fcms_xg6640000gn/T/ipykernel_4397/2007906347.py:25: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_election_t1 = pd.read_sql(query_election_t1, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best iteration:  999\n",
      "Accuracy: 99.99%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00        18\n",
      "           2       1.00      1.00      1.00      6819\n",
      "           3       1.00      1.00      1.00     30607\n",
      "           4       1.00      1.00      1.00        34\n",
      "           5       1.00      1.00      1.00        31\n",
      "           6       1.00      1.00      1.00        31\n",
      "           7       1.00      1.00      1.00        12\n",
      "           8       1.00      1.00      1.00     52054\n",
      "           9       1.00      1.00      1.00        72\n",
      "          10       1.00      1.00      1.00       578\n",
      "\n",
      "    accuracy                           1.00     90264\n",
      "   macro avg       1.00      1.00      1.00     90264\n",
      "weighted avg       1.00      1.00      1.00     90264\n",
      "\n",
      "[[    8     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0    18     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0  6812     7     0     0     0     0     0     0     0]\n",
      " [    0     0     0 30607     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0    34     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0    31     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0    31     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0    12     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0 52054     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0    72     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0   578]]\n",
      "CV Mean Score: 0.98%\n",
      "          Feature  Importance\n",
      "99   % Voix/Exp 5    0.214206\n",
      "101  % Voix/Exp 7    0.140777\n",
      "85   % Voix/Ins 3    0.139600\n",
      "97   % Voix/Exp 3    0.113323\n",
      "89   % Voix/Ins 7    0.098394\n",
      "..            ...         ...\n",
      "77        Parti 7    0.000000\n",
      "78        Parti 8    0.000000\n",
      "79        Parti 9    0.000000\n",
      "80       Parti 10    0.000000\n",
      "55          annee    0.000000\n",
      "\n",
      "[110 rows x 2 columns]\n",
      "Fitting 3 folds for each of 2187 candidates, totalling 6561 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 111\u001B[0m\n\u001B[1;32m     99\u001B[0m param_grid \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m7\u001B[39m],  \u001B[38;5;66;03m# Profondeur maximale de l'arbre\u001B[39;00m\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;241m0.05\u001B[39m, \u001B[38;5;241m0.1\u001B[39m],  \u001B[38;5;66;03m# Taux d'apprentissage\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreg_lambda\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1.5\u001B[39m, \u001B[38;5;241m2\u001B[39m]  \u001B[38;5;66;03m# L2 regularization\u001B[39;00m\n\u001B[1;32m    107\u001B[0m }\n\u001B[1;32m    109\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mmodel, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m    110\u001B[0m                            n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# 3-fold cross-validation\u001B[39;00m\n\u001B[0;32m--> 111\u001B[0m grid_search\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMeilleurs paramètres: \u001B[39m\u001B[38;5;124m\"\u001B[39m, grid_search\u001B[38;5;241m.\u001B[39mbest_params_)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMeilleure précision: \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(grid_search\u001B[38;5;241m.\u001B[39mbest_score_ \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    868\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    869\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    870\u001B[0m     )\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 874\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_search(evaluate_candidates)\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    878\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1386\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1387\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1388\u001B[0m     evaluate_candidates(ParameterGrid(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_grid))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    813\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    814\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    817\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    818\u001B[0m         )\n\u001B[1;32m    819\u001B[0m     )\n\u001B[0;32m--> 821\u001B[0m out \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[1;32m    822\u001B[0m     delayed(_fit_and_score)(\n\u001B[1;32m    823\u001B[0m         clone(base_estimator),\n\u001B[1;32m    824\u001B[0m         X,\n\u001B[1;32m    825\u001B[0m         y,\n\u001B[1;32m    826\u001B[0m         train\u001B[38;5;241m=\u001B[39mtrain,\n\u001B[1;32m    827\u001B[0m         test\u001B[38;5;241m=\u001B[39mtest,\n\u001B[1;32m    828\u001B[0m         parameters\u001B[38;5;241m=\u001B[39mparameters,\n\u001B[1;32m    829\u001B[0m         split_progress\u001B[38;5;241m=\u001B[39m(split_idx, n_splits),\n\u001B[1;32m    830\u001B[0m         candidate_progress\u001B[38;5;241m=\u001B[39m(cand_idx, n_candidates),\n\u001B[1;32m    831\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_and_score_kwargs,\n\u001B[1;32m    832\u001B[0m     )\n\u001B[1;32m    833\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001B[38;5;129;01min\u001B[39;00m product(\n\u001B[1;32m    834\u001B[0m         \u001B[38;5;28menumerate\u001B[39m(candidate_params), \u001B[38;5;28menumerate\u001B[39m(cv\u001B[38;5;241m.\u001B[39msplit(X, y, groups))\n\u001B[1;32m    835\u001B[0m     )\n\u001B[1;32m    836\u001B[0m )\n\u001B[1;32m    838\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    839\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    843\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     58\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     62\u001B[0m )\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1098\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1098\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretrieve()\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:975\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 975\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout))\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    977\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    564\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    565\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m future\u001B[38;5;241m.\u001B[39mresult(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:451\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 451\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         waiter\u001B[38;5;241m.\u001B[39macquire()\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "@",
   "id": "1ce8e8d767e7b591"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
